# ğŸ“ AI Blog Generator using LLaMA 2

This project is a **Streamlit-based web application** that generates professional blog content using the **LLaMA 2** language model. It allows users to input a topic, choose a target audience, and receive a structured blog post that ends with a clean and meaningful conclusion.

---

## ğŸš€ Features

- âœ… Topic-based blog generation using LLaMA 2
- âœ… Profession-specific writing style (e.g. Researchers, Freshers, etc.)
- âœ… Approximate word control (e.g. 300 words, no cutoff)
- âœ… Automatically trims incomplete or awkward endings
- âœ… User-friendly interface built with Streamlit
- âœ… Local `.bin` model integration using CTransformers

---

## ğŸ“¦ Installation

1. Clone the Repository
git clone https://github.com/yourusername/ai-blog-generator.git
cd ai-blog-generator

3. Install Required Packages
pip install -r requirements.txt

Or manually install:
pip install streamlit langchain ctransformers

ğŸ§  Model Setup
This project uses a locally hosted LLaMA 2 model in .bin format, compatible with CTransformers.
Update the model path in app.py to match your local setup:
model=r'D:\your\local\path\llama-2-7b-chat.ggmlv3.q8_0.bin'
Make sure your system has sufficient RAM/CPU to handle large language models locally.

â–¶ï¸ Running the App
In the project directory, run:
streamlit run app.py
Then open your browser and go to http://localhost:8501

âœ¨ How It Works
Enter a topic like â€œLinear Regressionâ€

Choose your audience style (e.g., Freshers)

Specify a word count (e.g., 300)

Click Generate and receive a structured blog that ends cleanly

ğŸ“ File Structure
â”œâ”€â”€ app.py               # Streamlit app with LLaMA integration
â”œâ”€â”€ README.md            # Project instructions and overview
â”œâ”€â”€ requirements.txt     # Python dependencies
â””â”€â”€ models/              # Folder where your local .bin model lives

ğŸ›  Technologies Used
Streamlit â€“ for UI
LangChain â€“ LLM orchestration
CTransformers â€“ for LLaMA 2 .bin support
LLaMA 2 â€“ language model by Meta


